{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMvpw+R/BKTJU9WoH4l2Wo+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilbaks/LLM_start/blob/main/02_Pytorch_Basics/02_pytorch_basics_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Pytorch Basics"
      ],
      "metadata": {
        "id": "7r4_5op0zbKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.Imports and Installs"
      ],
      "metadata": {
        "id": "vwjhN3czzyAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RbcVj73gzvmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Tensor basics"
      ],
      "metadata": {
        "id": "SvzuaM_Qzi0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything in pytorch is based on Tensor operations.\n",
        "A tensor can have different dimensions\n",
        "so it can be 1d, 2d, or even 3d and higher\n",
        "\n",
        "scalar, vector, matrix, tensor"
      ],
      "metadata": {
        "id": "ptugcXUY0SGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.empty(size): uninitiallized\n",
        "\n"
      ],
      "metadata": {
        "id": "f8g-nH100fMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(0)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5cPvFDk0_XL",
        "outputId": "b41ad829-12b1-4ab6-962a-7d12c79c7b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(1)  # scalar\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoE5-wYPza3w",
        "outputId": "b07f266c-da8c-4747-d262-21fbde5be2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.4082e-38])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmWD9cNpyuVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbee957a-a525-4ab8-ac79-2ab6ee0a28c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.7847e-04, 3.1896e-41, 4.0509e-04])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(3)  # vector\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 4) # matrix, 2D\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDvycCqB1M9d",
        "outputId": "bde5d271-c1e6-47bd-a33a-b2076856cbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.0334e-30,  7.0065e-45,  1.0790e-43,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2,4,6) # tensor, 3D\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9Vhptvy1a62",
        "outputId": "2940c257-bcc5-45b6-bc1f-ff60203dea38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.1715e-18, 2.6704e-06, 1.3679e+22, 2.0450e+20, 1.3484e-05,\n",
            "          8.2356e-10],\n",
            "         [6.7204e-07, 4.2886e-08, 4.2056e-05, 2.6102e-09, 1.4580e-19,\n",
            "          1.1495e+24],\n",
            "         [3.0881e+29, 1.5766e-19, 1.8889e+31, 7.2065e+31, 2.8404e+29,\n",
            "          2.3089e-12],\n",
            "         [1.9421e+31, 2.7491e+20, 6.1949e-04, 1.9421e+31, 2.7491e+20,\n",
            "          2.3078e-12]],\n",
            "\n",
            "        [[7.1760e+22, 7.2250e+28, 1.5766e-19, 4.2192e-08, 2.1666e-04,\n",
            "          3.2768e-09],\n",
            "         [8.5493e+20, 1.0386e+21, 2.1458e-07, 4.2252e-05, 8.3385e-10,\n",
            "          2.3053e-12],\n",
            "         [2.6302e+20, 6.1949e-04, 6.4805e-10, 2.5204e-09, 2.5928e-09,\n",
            "          6.9118e-04],\n",
            "         [6.7743e-10, 6.7122e-07, 2.7149e-06, 1.4580e-19, 4.5450e+30,\n",
            "          1.8524e+28]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.rand(size) random numbers from [0, 1]"
      ],
      "metadata": {
        "id": "kYP1ZLiW1vaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, 5)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIr7yMwg1osf",
        "outputId": "f5fec3ef-853f-47d8-a668-3309ccf8cf07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5742, 0.8729, 0.6403, 0.2695, 0.4463],\n",
            "        [0.8012, 0.3559, 0.3369, 0.0440, 0.6584],\n",
            "        [0.7371, 0.8095, 0.0812, 0.3585, 0.1946]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torch.zeros(size)\n",
        "- torch.ones(size)"
      ],
      "metadata": {
        "id": "8d9wroDp2Ha6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(3, 4, 5)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6QxRH3a19mj",
        "outputId": "b9d9ae23-1d0d-40e9-b26d-d44c51c2e7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones (1, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok8ZZclf2fZJ",
        "outputId": "f9ad4c5f-19ab-4a07-b2ff-bc4c2c8318ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- check size x.size()"
      ],
      "metadata": {
        "id": "-7uM3i0Q2oHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(4, 3, 5)\n",
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "895lkbnD2k94",
        "outputId": "d4e40cab-8ae8-4d43-9823-6f52aff19a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- check type"
      ],
      "metadata": {
        "id": "d937A3M92_Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWEBtgS32wEJ",
        "outputId": "b12db6eb-c45a-470d-a3ef-ba0360414af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### construct from data"
      ],
      "metadata": {
        "id": "SwGXlbkI3LCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px_uCWjb3Fpj",
        "outputId": "1a663d75-379f-417a-cc5f-60c007d6dbf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### requires grad argument"
      ],
      "metadata": {
        "id": "_JKan65J3ctT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeY60VdS3UfT",
        "outputId": "e36a8bf5-0284-4212-fe97-9c2ee46bb669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### operations"
      ],
      "metadata": {
        "id": "O1iZveHi3-nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2)\n",
        "y = torch.rand(2, 2)\n",
        "\n",
        "print(x, y)\n",
        "print(\"x + y=\", x + y)\n",
        "print(torch.add(x, y))\n",
        "print(y.add_(x))\n",
        "print(x - y)\n",
        "print(x * y)\n",
        "print(torch.mul(x, y))\n",
        "print(x / y)\n",
        "print( torch.div(x, y))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC5S8H8S31qL",
        "outputId": "2adee054-b614-4c26-d28b-578d4904fe29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8901, 0.2420],\n",
            "        [0.0595, 0.3032]]) tensor([[0.0094, 0.1762],\n",
            "        [0.5787, 0.7729]])\n",
            "x + y= tensor([[0.8995, 0.4181],\n",
            "        [0.6383, 1.0761]])\n",
            "tensor([[0.8995, 0.4181],\n",
            "        [0.6383, 1.0761]])\n",
            "tensor([[0.8995, 0.4181],\n",
            "        [0.6383, 1.0761]])\n",
            "tensor([[-0.0094, -0.1762],\n",
            "        [-0.5787, -0.7729]])\n",
            "tensor([[0.8007, 0.1012],\n",
            "        [0.0380, 0.3263]])\n",
            "tensor([[0.8007, 0.1012],\n",
            "        [0.0380, 0.3263]])\n",
            "tensor([[0.9896, 0.5787],\n",
            "        [0.0933, 0.2817]])\n",
            "tensor([[0.9896, 0.5787],\n",
            "        [0.0933, 0.2817]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcyTzXqE5OH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### slicing"
      ],
      "metadata": {
        "id": "jpjFU2hw5e0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(x[:, 0])  # all rows and 1 column\n",
        "print(x[0, : ])  # row 1 and all columns\n",
        "print(x[0, 0])# element at 1, 1\n",
        "print(x[0, 0].item())  # Get the actual value if only 1 element in your tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQMQWmsB4KvO",
        "outputId": "22c743e7-b17e-4420-d770-a2ed2b2f5c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6004, 0.5449, 0.6169],\n",
            "        [0.3612, 0.0161, 0.1193],\n",
            "        [0.1364, 0.2887, 0.3590],\n",
            "        [0.4113, 0.4350, 0.5988],\n",
            "        [0.6148, 0.8987, 0.5094]])\n",
            "tensor([0.6004, 0.3612, 0.1364, 0.4113, 0.6148])\n",
            "tensor([0.6004, 0.5449, 0.6169])\n",
            "tensor(0.6004)\n",
            "0.6003619432449341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6EtksmJf6h-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reshape"
      ],
      "metadata": {
        "id": "SudSjK6y6yvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "DsIqzbVs60cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.view(16)  # make in 1 dimension with 16\n",
        "z = x.view(-1, 8)  # make second dimension 8\n",
        "print(y, y.size())\n",
        "print(z, z.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUhVZna-68I7",
        "outputId": "411324b3-217b-4967-a6eb-14c2637f2f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7433, 0.6902, 0.4909, 0.0018, 0.1425, 0.3744, 0.0073, 0.1982, 0.0796,\n",
            "        0.0455, 0.9417, 0.3317, 0.1222, 0.6917, 0.3028, 0.4550]) torch.Size([16])\n",
            "tensor([[0.7433, 0.6902, 0.4909, 0.0018, 0.1425, 0.3744, 0.0073, 0.1982],\n",
            "        [0.0796, 0.0455, 0.9417, 0.3317, 0.1222, 0.6917, 0.3028, 0.4550]]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.dtype, type(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tISF9Yz_8HJu",
        "outputId": "d80c0935-fd84-4708-8bad-7808d9832e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy"
      ],
      "metadata": {
        "id": "ixFOXYWb7-OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch to numpy with .numpy()\n",
        "x = torch.ones(5)\n",
        "print(x)\n",
        "\n",
        "y = x.numpy()\n",
        "print(type(y), y)\n",
        "\n",
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9xS9ezq72oT",
        "outputId": "49229824-fa73-4891-8585-38439e60070e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'numpy.ndarray'> [1. 1. 1. 1. 1.]\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy to torch with .from_numpy(x)\n",
        "x = np.ones(5)\n",
        "y = torch.from_numpy(x)\n",
        "print(y)\n",
        "\n",
        "# again be careful when modifying\n",
        "x += 1\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA1pHO6r84gL",
        "outputId": "af9787ed-7dcd-4a21-e79a-633b2554fea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xpDxELHf9Yru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tensors on CPU or on GPU"
      ],
      "metadata": {
        "id": "pLrVzyHX9kpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    y = torch.ones_like(x,device=device)\n",
        "    x = x.to(device)\n",
        "    z = x + y\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")\n",
        "    z = z.numpy()"
      ],
      "metadata": {
        "id": "Z2hg9jaB9rDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "moarOvqN9qOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Autograd"
      ],
      "metadata": {
        "id": "PycXRLy2IXEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. General intutions"
      ],
      "metadata": {
        "id": "kFbiXTdGQKxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "0gJVod6EIaG6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The autograd package provides automatic differentiation\n",
        "# for all operations on Tensors\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "print(y)\n",
        "y.backward()  # RuntimeError: grad can be implicitly created only for scalar outputs"
      ],
      "metadata": {
        "id": "ojn4wag-IpvX",
        "outputId": "c4681c1c-644d-4edf-f99b-47f982c0dec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.1488,  0.9591,  0.0400], requires_grad=True)\n",
            "tensor([0.8512, 2.9591, 2.0400], grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e8a5df4a52f5>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# RuntimeError: grad can be implicitly created only for scalar outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                     raise RuntimeError(\n\u001b[0m\u001b[1;32m    118\u001b[0m                         \u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- scalar case"
      ],
      "metadata": {
        "id": "IRrdi69FLspl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "print(y)  # (x0 + 2, x1 + 2 , x2 + 2)\n",
        "y = y.sum()  # (x0 + 2 + x1 + 2 + x2 + 2)\n",
        "print(y)\n",
        "y.backward()\n",
        "print(x.grad)  # dy/dx0 ,  dy/dx1, dy/dx2"
      ],
      "metadata": {
        "id": "Fq64vbPnLqBl",
        "outputId": "88a138af-9e22-4161-a325-363b7404f915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7094, -1.0397, -1.3205], requires_grad=True)\n",
            "tensor([1.2906, 0.9603, 0.6795], grad_fn=<AddBackward0>)\n",
            "tensor(2.9305, grad_fn=<SumBackward0>)\n",
            "tensor([1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- non-scalar case"
      ],
      "metadata": {
        "id": "sFYesdJRM_tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "print(x.grad)\n",
        "y = x + 2\n",
        "print(y)\n",
        "grad_output = torch.ones(3)\n",
        "print(grad_output)\n",
        "y.backward(grad_output)\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "print(x.grad)  # Provide the gradient argument\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
        "# It computes partial derivates while applying the chain rule"
      ],
      "metadata": {
        "id": "-E3A6VveNF6i",
        "outputId": "95fb81d7-0a9c-47c4-ef54-ee53d70958c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.0923, -0.2658, -0.0159], requires_grad=True)\n",
            "None\n",
            "tensor([3.0924, 1.7342, 1.9841], grad_fn=<AddBackward0>)\n",
            "tensor([1., 1., 1.])\n",
            "None\n",
            "tensor([1.0000e-01, 1.0000e+00, 1.0000e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "print(x.grad)  # Provide the gradient argument\n",
        "y = x + 2\n",
        "print(y)\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)  # dy/dx\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eC6sEidRMTu",
        "outputId": "06a5eb3e-de88-4803-8102-f425a5d429df"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([1.6487, 2.4264, 1.7382], grad_fn=<AddBackward0>)\n",
            "tensor([1.0000e-01, 1.0000e+00, 1.0000e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.Stop a tensor from tracking history:"
      ],
      "metadata": {
        "id": "Ci8mh3kqRnpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For example during our training loop when we want to update our weights\n",
        "# then this update operation should not be part of the gradient computation\n",
        "# - x.requires_grad_(False)\n",
        "# - x.detach()\n",
        "# - wrap in 'with torch.no_grad():'\n",
        "\n",
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "print(f\"{a.requires_grad=}\")\n",
        "b = ((a * 3) / (a - 1))\n",
        "print(f\"{b.grad_fn=}\")\n",
        "a.requires_grad_(True)\n",
        "print(f\"{a.requires_grad=}\")\n",
        "b = (a * a).sum()\n",
        "print(f\"{b.grad_fn=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQS-aqW6T7YY",
        "outputId": "dd9d827a-6460-47ef-bf30-e152d72aaaa5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.requires_grad=False\n",
            "b.grad_fn=None\n",
            "a.requires_grad=True\n",
            "b.grad_fn=<SumBackward0 object at 0x796dd85a70d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(f\"{a.requires_grad=}\")\n",
        "b = a.detach()\n",
        "print(f\"{b.requires_grad=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe8BBi1VT968",
        "outputId": "1fb1fd51-4fa8-4257-a2cb-87d738a64cbc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.requires_grad=True\n",
            "b.requires_grad=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(f\"{a.requires_grad=}\")\n",
        "with torch.no_grad():\n",
        "    print(f\"{(x ** 2).requires_grad=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLiU4HeFT_3z",
        "outputId": "681f91b0-2268-4762-dd41-a99daedcb939"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.requires_grad=True\n",
            "(x ** 2).requires_grad=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.Zero gradients"
      ],
      "metadata": {
        "id": "7M0uKkeWUCKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!!\n",
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "print(f\"{weights=}\")\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    print(f\"{model_output=}\")\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    # optimize model, i.e. adjust weights...\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(f\"{weights=}\")\n",
        "print(f\"{model_output=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0as4DNO8UItG",
        "outputId": "ffbcb0f5-4a43-4a4f-d60b-6be12884d41e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights=tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "model_output=tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "model_output=tensor(8.4000, grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "model_output=tensor(4.8000, grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "weights=tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "model_output=tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Backpropagation"
      ],
      "metadata": {
        "id": "IXg35BlhZZla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(f\"{loss=}\")\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(f\"{w.grad=}\")\n",
        "\n",
        "# update weights\n",
        "# next forward and backward pass...\n",
        "\n",
        "# continue optimizing:\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()\n",
        "\n",
        "# next forward and backward pass..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC-PcGIBZc8Z",
        "outputId": "5e6be86b-fade-45c8-88ea-3643d6e19182"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss=tensor(1., grad_fn=<PowBackward0>)\n",
            "w.grad=tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Gradient descent"
      ],
      "metadata": {
        "id": "LoKXoXYAl08L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Manually"
      ],
      "metadata": {
        "id": "InLauSnnl7x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute every step manually\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "print(f\"{X=}\")\n",
        "print(f\"{Y=}\")\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# J = MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N * 2x(w*x - y)\n",
        "def gradient(x, y, y_pred):\n",
        "    return np.mean(2*x*(y_pred - y))\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "    # update weights\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOs6qkUl5qt",
        "outputId": "36d518ad-2335-4a03-cef1-25544cc5f2c9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X=array([1., 2., 3., 4.], dtype=float32)\n",
            "Y=array([2., 4., 6., 8.], dtype=float32)\n",
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 3: w = 0.772, loss = 15.66018677\n",
            "epoch 5: w = 1.113, loss = 8.17471600\n",
            "epoch 7: w = 1.359, loss = 4.26725292\n",
            "epoch 9: w = 1.537, loss = 2.22753215\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 13: w = 1.758, loss = 0.60698175\n",
            "epoch 15: w = 1.825, loss = 0.31684822\n",
            "epoch 17: w = 1.874, loss = 0.16539653\n",
            "epoch 19: w = 1.909, loss = 0.08633806\n",
            "Prediction after training: f(5) = 9.612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.Auto"
      ],
      "metadata": {
        "id": "Acu2DhnXsGEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Here we replace the manually computed gradient with autograd\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG3x3IfYsIHQ",
        "outputId": "ce5cc3b2-0a95-4668-d928-0d307c3e00c3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Loss and optimizer"
      ],
      "metadata": {
        "id": "o5P9MSDtwD7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model (input, output, forward pass with different layers)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#       - Forward = compute prediction and loss\n",
        "#       - Backward = compute gradients\n",
        "#       - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model: Weights to optimize and forward function\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# callable function\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_predicted = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1gSYyJcwHaY",
        "outputId": "8788e46d-67a9-4833-f898-c523d8fb5323"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch  1 : w =  tensor(0.3000, requires_grad=True)  loss =  tensor(30., grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  tensor(1.6653, requires_grad=True)  loss =  tensor(1.1628, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  tensor(1.9341, requires_grad=True)  loss =  tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  tensor(1.9870, requires_grad=True)  loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  tensor(1.9974, requires_grad=True)  loss =  tensor(6.7705e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  tensor(1.9995, requires_grad=True)  loss =  tensor(2.6244e-06, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  tensor(1.9999, requires_grad=True)  loss =  tensor(1.0176e-07, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(3.9742e-09, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(1.4670e-10, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(5.0768e-12, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Linear regression"
      ],
      "metadata": {
        "id": "6QjnhoBBvNtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries\n",
        "import torch  # Main PyTorch library for tensors\n",
        "import torch.nn as nn  # Neural network module in PyTorch\n",
        "import numpy as np\n",
        "from sklearn import datasets  # To import datasets for regression\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "xEgaQrfVvgkF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Prepare Data\n",
        "\n",
        "# Generate a regression dataset with 100 samples, 1 feature, added noise, and a random state for reproducibility\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# Convert the numpy arrays into PyTorch tensors and ensure the data type is float32 (suitable for PyTorch models)\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "\n",
        "# Reshape y to make it a column vector\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "# Determine the number of samples and features from the dataset for later use\n",
        "n_samples, n_features = X.shape\n"
      ],
      "metadata": {
        "id": "pZ0jYN6Vv0PS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "# Define the input and output sizes for the linear regression model (1 feature in, 1 value out)\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "\n",
        "# Initialize the linear model from PyTorch's neural network module\n",
        "model = nn.Linear(input_size, output_size)"
      ],
      "metadata": {
        "id": "W9ipt8lgwaLx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Loss and optimizer\n",
        "# Define the learning rate for the optimization algorithm\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Set the loss function as Mean Squared Error, common for regression tasks\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define the optimizer to use Stochastic Gradient Descent and pass the model's parameters and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "RrO4Xtp3wnlZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Training loop\n",
        "# Define the number of epochs, or iterations over the entire dataset\n",
        "num_epochs = 100\n",
        "\n",
        "# Start the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass: Compute the predicted y by passing x to the model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # Compute the loss between the predicted y and the true y\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass: Compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the model parameters using the gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # Zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6UrvIiQwxu1",
        "outputId": "79e99753-489e-408f-cf90-f272291cf91e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 373.2370\n",
            "epoch: 20, loss = 346.9342\n",
            "epoch: 30, loss = 328.9650\n",
            "epoch: 40, loss = 316.6871\n",
            "epoch: 50, loss = 308.2966\n",
            "epoch: 60, loss = 302.5619\n",
            "epoch: 70, loss = 298.6415\n",
            "epoch: 80, loss = 295.9612\n",
            "epoch: 90, loss = 294.1284\n",
            "epoch: 100, loss = 292.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "# Detach the predicted y values from the graph and convert them to a numpy array for plotting\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "# Plot the original data points\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "\n",
        "# Plot the line of best fit predicted by the model\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "sja9jYEAw0Tx",
        "outputId": "12f0bbc0-42fd-4abd-f606-bef4729c1fd1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.Logistic regression"
      ],
      "metadata": {
        "id": "wTbgqhr6w9Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "43W58nwjx2pg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Prepare data\n",
        "# Load the Breast Cancer dataset from sklearn datasets\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target  # Extract features and target labels\n",
        "\n",
        "n_samples, n_features = X.shape  # Determine the number of samples and features\n",
        "\n",
        "# Split the data into 80% training and 20% testing, with a random state for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# Initialize a StandardScaler to normalize the features by removing the mean and scaling to unit variance\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)  # Fit to the training data and transform it\n",
        "X_test = sc.transform(X_test)  # Transform the test data\n",
        "\n",
        "# Convert the numpy arrays to PyTorch tensors and ensure they are of type float32\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "# Reshape the target tensors to make them two-dimensional (necessary for BCELoss later on)\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n"
      ],
      "metadata": {
        "id": "dtDmtUrGx4rV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Model\n",
        "# Define a PyTorch class for the logistic regression model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        # Define a linear layer with a single output (for the binary classification)\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply the sigmoid activation function to the output of the linear layer\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "# Initialize the model using the number of features from the dataset\n",
        "model = Model(n_features)\n"
      ],
      "metadata": {
        "id": "sbxIznzMyU1P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Loss and optimizer\n",
        "num_epochs = 100  # Define the number of iterations over the whole dataset\n",
        "learning_rate = 0.01  # Define the learning rate for the optimizer\n",
        "\n",
        "# Use Binary Cross Entropy Loss for the binary classification task\n",
        "criterion = nn.BCELoss()\n",
        "# Define the optimizer as Stochastic Gradient Descent, pass the model parameters and the learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "j6T49FvEymUO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(X_train)\n",
        "    # Compute and print loss using the true labels and the predictions from the model\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass: Compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "    # Update the model parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Zero the gradients to prevent them from accumulating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "rgM5EULyyuNK",
        "outputId": "302b9e59-6235-4d7b-be34-b40f58de1908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.5383\n",
            "epoch: 20, loss = 0.4550\n",
            "epoch: 30, loss = 0.4002\n",
            "epoch: 40, loss = 0.3611\n",
            "epoch: 50, loss = 0.3315\n",
            "epoch: 60, loss = 0.3081\n",
            "epoch: 70, loss = 0.2890\n",
            "epoch: 80, loss = 0.2731\n",
            "epoch: 90, loss = 0.2596\n",
            "epoch: 100, loss = 0.2479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():  # Temporarily set all the requires_grad flag to false\n",
        "    y_predicted = model(X_test)  # Predict the labels for the test set\n",
        "    y_predicted_cls = y_predicted.round()  # Round the predictions to 0 or 1\n",
        "    # Calculate the accuracy as the number of correct predictions divided by the total number of predictions\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')  # Print the accuracy\n"
      ],
      "metadata": {
        "id": "5cCvug7yy2yc",
        "outputId": "447c9824-abc7-45f2-a245-b43c8b5c7b60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8947\n"
          ]
        }
      ]
    }
  ]
}